"""
rag.py
Sistema H√≠brido: Global Lore (Google Gemini) + Session Memory.
Mant√©m compatibilidade com indexa√ß√£o de arquivos de texto e busca contextual.
"""
import os
from typing import List, Optional
from langchain_community.vectorstores import FAISS
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv

load_dotenv()

# Configura√ß√µes de Caminho
SAVES_DIR = "data/saves_memory" # Pasta onde ficam os vetores dos saves individuais

_embeddings: Optional[GoogleGenerativeAIEmbeddings] = None

def get_embeddings() -> Optional[GoogleGenerativeAIEmbeddings]:
    """Inicializa embeddings do Google sob demanda."""
    global _embeddings
    if _embeddings:
        return _embeddings

    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("[RAG] GOOGLE_API_KEY n√£o configurada. Embeddings desativados.")
        return None

    try:
        _embeddings = GoogleGenerativeAIEmbeddings(model="models/text-embedding-004")
    except Exception as exc:
        print(f"[RAG] Falha ao inicializar embeddings: {exc}")
        _embeddings = None

    return _embeddings

def get_global_db_path(index_name: str) -> str:
    """Retorna o nome da pasta do √≠ndice GLOBAL (lore ou rules)."""
    return f"faiss_{index_name}_index"

def _get_session_path(game_id: str) -> str:
    """Retorna o caminho da pasta de mem√≥ria da SESS√ÉO espec√≠fica."""
    return os.path.join(SAVES_DIR, game_id)

def query_rag(query: str, index_name: str = "lore", game_id: Optional[str] = None) -> str:
    """
    Busca contexto de forma h√≠brida:
    1. √çndice Global (Lore/Regras) - Imut√°vel durante o jogo.
    2. √çndice da Sess√£o (Mem√≥rias do Save) - Din√¢mico, se game_id for fornecido.
    """
    embeddings = get_embeddings()
    if not embeddings: return ""

    results = []

    # 1. Busca Global (Baseado no index_name: 'lore' ou 'rules')
    global_path = get_global_db_path(index_name)
    if os.path.exists(global_path):
        try:
            global_db = FAISS.load_local(global_path, embeddings, allow_dangerous_deserialization=True)
            # Busca 2 chunks globais
            results.extend(global_db.similarity_search(query, k=2))
        except Exception as e:
            print(f"‚ö†Ô∏è [RAG] Erro ao ler Global '{index_name}': {e}")

    # 2. Busca na Sess√£o (Se houver game_id)
    # A mem√≥ria da sess√£o √© agn√≥stica ao index_name (√© tudo "mem√≥ria do jogo")
    if game_id:
        session_path = _get_session_path(game_id)
        if os.path.exists(session_path):
            try:
                session_db = FAISS.load_local(session_path, embeddings, allow_dangerous_deserialization=True)
                # Busca +2 chunks pessoais
                results.extend(session_db.similarity_search(query, k=2))
            except Exception:
                pass 
    
    if not results: return ""
    
    # Formata e desduplica
    seen = set()
    final_text = []
    for doc in results:
        content = doc.page_content.strip()
        if content not in seen:
            seen.add(content)
            # Adiciona prefixo para ajudar a IA a saber a fonte
            # (Opcional, mas ajuda a distinguir Regra de Mem√≥ria)
            final_text.append(content)
            
    return "\n---\n".join(final_text)

def add_memory_to_session(game_id: str, texts: List[str]):
    """
    Adiciona novas mem√≥rias ao √≠ndice espec√≠fico deste save (game_id).
    """
    if not game_id or not texts: return

    embeddings = get_embeddings()
    if not embeddings: return

    session_path = _get_session_path(game_id)
    
    try:
        if os.path.exists(session_path):
            # Carrega existente
            db = FAISS.load_local(session_path, embeddings, allow_dangerous_deserialization=True)
            db.add_texts(texts)
        else:
            # Cria novo
            if not os.path.exists(SAVES_DIR): os.makedirs(SAVES_DIR)
            db = FAISS.from_texts(texts, embeddings)

        # Salva
        db.save_local(session_path)
        print(f"üíæ [RAG] Mem√≥ria salva para sess√£o '{game_id}': +{len(texts)} fatos.")
        
    except Exception as e:
        print(f"‚ùå [RAG ERROR] Falha ao salvar mem√≥ria: {e}")

# --- FUN√á√ïES DE UTILIDADE (Setup Inicial) ---

def ingest_file(file_path: str, index_name: str):
    """
    Ingere um arquivo de texto para criar os √≠ndices GLOBAIS (lore/rules).
    Use isso no setup ou quando alterar o world_lore.txt.
    """
    if not os.path.exists(file_path):
        print(f"[ERRO] Arquivo n√£o encontrado: {file_path}")
        return

    embeddings = get_embeddings()
    if embeddings is None: return

    print(f"--- INGEST√ÉO: {file_path} -> √çNDICE: {index_name} ---")
    
    loader = TextLoader(file_path, encoding='utf-8')
    docs = loader.load()
    
    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    chunks = splitter.split_documents(docs)
    
    # Salva no caminho global
    path = get_global_db_path(index_name)
    db = FAISS.from_documents(chunks, embeddings)
    db.save_local(path)
    print(f"‚úÖ Indexado com sucesso em '{path}'!")

if __name__ == "__main__":
    # Script r√°pido para re-gerar a Lore Global se rodar este arquivo direto
    print("Recriando √≠ndices globais...")
    if os.path.exists("world_lore.txt"):
        ingest_file("world_lore.txt", "lore")
    if os.path.exists("rules.txt"):
        ingest_file("rules.txt", "rules")